from __future__ import division
from __future__ import print_function
from __future__ import absolute_import
import warnings

warnings.filterwarnings("ignore")

import random
import pprint
import sys
import time
import numpy as np
from optparse import OptionParser
import pickle
import math
import cv2
import copy
from matplotlib import pyplot as plt

from sklearn.metrics import average_precision_score
import keras
import tensorflow as tf
from keras import backend as K
from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout
from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed
from keras.utils import layer_utils
from keras.utils.data_utils import get_file

from keras.models import Model
from keras.utils import generic_utils
from keras import initializers, regularizers
import Data_Preparation as dp

train_images, train_boxes, test_images, test_boxes = dp.get_dataset()


def get_data():
    all_imgs = {}

    for i in range(len(train_images)):  # 0 name ,1 image

        all_imgs[train_images[i][0]] = {}
        (rows, cols) = train_images[i][1].shape[:2]
        all_imgs[train_images[i][0]]['file_name'] = train_images[i][0]
        all_imgs[train_images[i][0]]['width'] = cols
        all_imgs[train_images[i][0]]['height'] = rows
        all_imgs[train_images[i][0]]['bboxes'] = []
        for j in range(len(train_boxes[i])):
            value = train_boxes[i][j].strip().split(',')
            all_imgs[train_images[i][0]]['bboxes'].append(
                {'x1': int(value[0]), 'x2': int(value[1]), 'y1': int(value[2]), 'y2': int(value[3])})
        all_data = []

        for key in all_imgs:
            all_data.append(all_imgs[key])

    # all_data[no] = all data of image
    return all_data


class Config:
    def __init__(self):
        # Print the process or not
        self.verbose = True

        # Name of base network
        self.network = 'vgg'

        # Setting for data augmentation
        self.use_horizontal_flips = False
        self.use_vertical_flips = False
        self.rot_90 = False

        # Anchor box scales
        # Note that if im_size is smaller, anchor_box_scales should be scaled
        # Original anchor_box_scales in the paper is [128, 256, 512]
        self.anchor_box_scales = [64, 128, 256]

        # Anchor box ratios
        self.anchor_box_ratios = [[1, 1], [1. / math.sqrt(2), 2. / math.sqrt(2)],
                                  [2. / math.sqrt(2), 1. / math.sqrt(2)]]

        # Size to resize the smallest side of the image
        # Original setting in paper is 600. Set to 300 in here to save training time
        self.im_size = 300

        # image channel-wise mean to subtract
        self.img_channel_mean = [103.939, 116.779, 123.68]
        self.img_scaling_factor = 1.0

        # number of ROIs at once
        self.num_rois = 4  ##?

        # stride at the RPN (this depends on the network configuration)
        self.rpn_stride = 16  ##?

        self.balanced_classes = False

        # scaling the stdev ??????????????????????????
        self.std_scaling = 4.0
        self.classifier_regr_std = [8.0, 8.0, 4.0, 4.0]
        ##### leh alvalues de fel overlapping
        # overlaps for RPN
        self.rpn_min_overlap = 0.3
        self.rpn_max_overlap = 0.7

        # overlaps for classifier ROIs
        self.classifier_min_overlap = 0.1
        self.classifier_max_overlap = 0.5

        # placeholder for the class mapping, automatically generated by the parser
        self.class_mapping = None

        self.model_path = None


x = get_data()

print(x[7])
